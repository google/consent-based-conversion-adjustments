{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1LyGCNZhWBH"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/google/consent-based-conversion-adjustments/blob/main/cocoa/cocoa_template.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/google/consent-based-conversion-adjustments/blob/main/cocoa/cocoa_template.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLQsEboILf9_"
      },
      "source": [
        "###### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMCxIddRJkps"
      },
      "source": [
        " Copyright 2020 Google LLC\n",
        "\n",
        " Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " you may not use this file except in compliance with the License.\n",
        " You may obtain a copy of the License at\n",
        "\n",
        "      http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        " Unless required by applicable law or agreed to in writing, software\n",
        " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " See the License for the specific language governing permissions and\n",
        " limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RwBf7lfJxPs"
      },
      "source": [
        "# Consent-based Conversion Adjustments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rGQ-Vm1Lnh_"
      },
      "source": [
        "In this notebook, we are illustrating how we can use a non-parametric model (based on k nearest-neighbors) to redistribute conversion values of customers opting out of advertising cookies over customers who opt in. \n",
        "The resulting conversion-value adjustments can be used within value-based bidding to prevent biases in the bidding-algorithm due to systematic differences between customers who opt in vs customers who don't."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IENCIRJNyqF"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLBUAG1O5S2S"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/google/consent-based-conversion-adjustments.git\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRAT4tTpZY51"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "import typing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "np.random.seed(123)  \n",
        "\n",
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIfB_qb851sE"
      },
      "outputs": [],
      "source": [
        "from cocoa import nearest_consented_customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK9vYsW8N7F3"
      },
      "source": [
        "# Data Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N21wIR0hbCTb"
      },
      "outputs": [],
      "source": [
        "#@title Create fake dataset of adgroups and conversion values\n",
        "#@markdown We are generating random data: each row is an individual conversion\n",
        "#@markdown with a given conversion value. \\\n",
        "#@markdown For each conversion, we know the\n",
        "#@markdown adgroup, which is our only feature here and just consists of 3 letters.\n",
        "\n",
        "n_consenting_customers = 8000  #@param\n",
        "n_nonconsenting_customers = 2000  #@param\n",
        "\n",
        "\n",
        "def simulate_conversion_data_consenting_non_consenting(\n",
        "    n_consenting_customers: int,\n",
        "    n_nonconsenting_customers: int) -\u003e typing.Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "  \"\"\"Simulates dataframes for consenting and non-consenting customers.\n",
        "\n",
        "    Args:\n",
        "      n_consenting_customers: Desired number of consenting customers. Should be\n",
        "        larger than n_nonconsenting_customers.\n",
        "      n_nonconsenting_customers: Desired number non non-consenting customers.\n",
        "\n",
        "    Returns:\n",
        "      Two dataframes of simulated consenting and non-consenting customers.\n",
        "  \"\"\"\n",
        "  fake_adgroups = np.array(\n",
        "      ['_'.join(fake_ad) for fake_ad in (combinations('ABCDEFG', 3))])\n",
        "\n",
        "  data_consenting = pd.DataFrame.from_dict({\n",
        "      'adgroup':\n",
        "          fake_adgroups[np.random.randint(\n",
        "              low=0, high=len(fake_adgroups), size=n_consenting_customers)],\n",
        "      'conversion_value':\n",
        "          np.random.lognormal(1, size=n_consenting_customers)\n",
        "  })\n",
        "\n",
        "  data_nonconsenting = pd.DataFrame.from_dict({\n",
        "      'adgroup':\n",
        "          fake_adgroups[np.random.randint(\n",
        "              low=0, high=len(fake_adgroups), size=n_nonconsenting_customers)],\n",
        "      'conversion_value':\n",
        "          np.random.lognormal(1, size=n_nonconsenting_customers)\n",
        "  })\n",
        "  return data_consenting, data_nonconsenting\n",
        "\n",
        "\n",
        "data_consenting, data_nonconsenting = simulate_conversion_data_consenting_non_consenting(\n",
        "    n_consenting_customers, n_nonconsenting_customers)\n",
        "data_consenting.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_9JEHeZOF8X"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K-WQvtKYdn6N"
      },
      "outputs": [],
      "source": [
        "#@title Split adgroups in separate levels\n",
        "#@markdown We preprocess our data. Consenting and non-consenting data are\n",
        "#@markdown concatenated to ensure that they have the same feature-columns. \\\n",
        "#@markdown We then split our adgroup-string into its components and dummy code each.\n",
        "#@markdown The level of each letter in the adgroup-string is added as prefix here.\n",
        "\n",
        "def preprocess_data(data_consenting, data_nonconsenting):\n",
        "  data_consenting['consent'] = 1\n",
        "  data_nonconsenting['consent'] = 0\n",
        "  data_all = pd.concat([data_consenting, data_nonconsenting])\n",
        "  data_all.reset_index(inplace=True)\n",
        "\n",
        "  # split the adgroups in their levels and dummy-code those.\n",
        "  data_all = data_all.join(\n",
        "      pd.get_dummies(data_all['adgroup'].str.split('_').apply(pd.Series)))\n",
        "  data_all.drop(['adgroup'], axis=1, inplace=True)\n",
        "  return data_all[data_all['consent'] == 1], data_all[data_all['consent'] == 0]\n",
        "\n",
        "data_consenting, data_nonconsenting = preprocess_data(data_consenting,\n",
        "                                                      data_nonconsenting)\n",
        "data_consenting.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v16SF-umvAz"
      },
      "source": [
        "# Create NearestCustomerMatcher object and run conversion-adjustments.\n",
        "\n",
        "We now have our fake data in the right format – similarity here depends alone on\n",
        "the adgroup of a given customer. In reality, we would have a gCLID and a\n",
        "timestamp for each customer that we could pass as `id_columns` to the matcher.\\\n",
        "Other example features that could be used instead/in addition to the adgroup are\n",
        "\n",
        "\n",
        "* device type\n",
        "* geo\n",
        "* time of day\n",
        "* ad-type\n",
        "* GA-derived features\n",
        "* etc. \n",
        "\n",
        "When using the `NearestCustomerMatcher`, we can choose between three matching\n",
        "strategies:\n",
        "* if we define `number_nearest_neighbors`, a fixed number of nearest (consenting)\n",
        "customers is used, irrespective of how dissimilar those customers are to the \n",
        "seed-non-consenting customer.\n",
        "* if we define `radius`, all consenting customers that fall within the specified radius of a non-consenting customer are used. This means that the number of nearest-neighbors likely differs between non-consenting customers, and a given non-consenting customer might have no consenting customers in their radius.\n",
        "* if we define `percentage`, the `NearestCustomerMatcher` first which minimal radius needs to be set in order to find at least one closest consenting customer for at least `percentage` non-consenting customers (not implemented in beam yet)\n",
        "\n",
        "In practice, the simplest approach is to set `number_nearest_neighbors` and\n",
        "choose a sufficiently high number here to ensure that individual consenting\n",
        "customers do not receive too high a share of non-consenting conversion values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezsCLpQ4jExj"
      },
      "outputs": [],
      "source": [
        "matcher = nearest_consented_customers.NearestCustomerMatcher(\n",
        "    data_consenting, conversion_column='conversion_value', id_columns=['index'])\n",
        "data_adjusted = matcher.calculate_adjusted_conversions(\n",
        "    data_nonconsenting, number_nearest_neighbors=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GCEKmfcdqyRK"
      },
      "outputs": [],
      "source": [
        "#@title We generated a new dataframe containing the conversion-value adjustments\n",
        "data_adjusted.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "twOhpxSvmIkR"
      },
      "outputs": [],
      "source": [
        "#@title Visualise distribution of adjusted conversions\n",
        "#@markdown We can plot the original and adjusted (original + adjustment-values)\n",
        "#@markdown conversion values and see that in general, the distributions are\n",
        "#@markdown very similar, but as expected, the adjusted values are shifted towards\n",
        "#@markdown larger values.\n",
        "ax = data_adjusted['conversion_value'].plot(kind='hist', alpha=.5, )\n",
        "(data_adjusted['adjusted_conversion']+data_adjusted['conversion_value']).plot(kind='hist', ax=ax, alpha=.5)\n",
        "ax.legend(['original conversion value', 'adjusted conversion value'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjDO7pncOTON"
      },
      "source": [
        "# Next steps\n",
        "The above would run automatically on a daily basis within a Google Cloud Project. A new table ready to use with Offline Conversion Import is created.\n",
        "If no custom pipeline has been set up yet, we recommend using [Tentacles](https://github.com/GoogleCloudPlatform/cloud-for-marketing/blob/master/marketing-analytics/activation/gmp-googleads-connector/README.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5kV_6qNPSNF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QK9vYsW8N7F3",
        "V_9JEHeZOF8X",
        "3v16SF-umvAz"
      ],
      "last_runtime": {
        "build_target": "//corp/gtech/ads/infrastructure/colab_utils/ds_runtime:ds_colab",
        "kind": "private"
      },
      "name": "cocoa_template.ipynb",
      "provenance": [
        {
          "file_id": "1YafoEaxHj4Gfs51FwMEzEjx1oRu92XSB",
          "timestamp": 1619712681367
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
